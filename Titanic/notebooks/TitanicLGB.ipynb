{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Titanic, ML from Disaster (II) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Brull Borr√†s, Pere Miquel, 28/01/2018. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4 Modelling**\n",
    "    - Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules for Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import lightgbm as lgb\n",
    "\n",
    "# And for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "\n",
    "# Load processed datasets from previous notebook\n",
    "train = pd.read_csv(\"../input/processed_train.csv\", sep = \",\")\n",
    "test = pd.read_csv(\"../input/processed_test.csv\", sep = \",\")\n",
    "test_id = test['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, what happened so far?\n",
    "\n",
    "- Loaded and visualized data trying to get an idea of relation between explanatory variables and the response variable or target.\n",
    "- Created new features trying to exploit hidden data and increase the effect on the target.\n",
    "- Encoded categorical variables.\n",
    "- Dropped useless information.\n",
    "\n",
    "We are now left with a numerical matrix of data. Training dataset will get splitted into a train set which will correspond to the data used to fit the model and a validation set to assess performance. Then, the best parameters for the model will be looked for using the GridSearch technique, which iterates over all possible combinations and outputs the best one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Survived']\n",
    "y_test = test['PassengerId']\n",
    "X_train = train.drop(['Survived'], axis=1)\n",
    "X_test = test.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets\n",
    "x, x_val, y, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm containers\n",
    "lgb_train = lgb.Dataset(x, y)\n",
    "lgb_eval = lgb.Dataset(x_val, y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {'boosting_type': 'gbdt', \n",
    "          'colsample_bytree': 0.64, \n",
    "          'learning_rate': 0.1, \n",
    "          'n_estimators': 64, \n",
    "          'num_leaves': 8, \n",
    "          'objective': 'binary', \n",
    "          'random_state': 501, \n",
    "          'feature_fraction': 0.5,\n",
    "          'bagging_fraction': 0.5,\n",
    "          'bagging_freq': 20,\n",
    "          'reg_alpha': 1, \n",
    "          'reg_lambda': 1.2, \n",
    "          'subsample': 0.75,\n",
    "          'max_depth': -1,\n",
    "          'subsample_for_bin': 200,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.01,0.05,0.1],\n",
    "    'n_estimators': [100,200,300],\n",
    "    'num_leaves': [8,10,12],\n",
    "    'max_depth': [3,4],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'seed' : [777],\n",
    "    'colsample_bytree' : [0.7,0.85,1],\n",
    "    'subsample' : [0.7,0.85,1],\n",
    "    'reg_alpha' : [0,0.5,1],\n",
    "    'reg_lambda' : [0,2,6,7,10],\n",
    "    'max_depth': [4,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7290 candidates, totalling 29160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 29160 out of 29160 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.85, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300, 'num_leaves': 8, 'objective': 'binary', 'reg_alpha': 1, 'reg_lambda': 10, 'seed': 777, 'subsample': 1}\n",
      "0.8361391694725028\n"
     ]
    }
   ],
   "source": [
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = -1, # Updated from 'nthread' \n",
    "          silent = True)\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.85, 'learning_rate': 0.1, 'max_depth': 4, \n",
    "               'n_estimators': 300, 'num_leaves': 8, 'objective': 'binary', 'reg_alpha': 1, 'reg_lambda': 10,\n",
    "               'seed': 777, 'subsample': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-e0c1cbf40bdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.2f%% (%.2f%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "mdl.set_params(**best_params)\n",
    "mdl.fit(X_train,y_train)\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(mdl, np.array(X_val), np.array(y_val), cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "lgb.plot_importance(mdl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'PassengerId': test_id,'Survived': y_pred}, columns=['PassengerId','Survived'])\n",
    "result['Survived'] = result['Survived'].map(lambda x: 1 if x>0.5 else 0)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../output/sub4_lgb.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
